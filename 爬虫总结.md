# 爬虫初窥 #
----------
大数据环境下，数据分析已由业务驱动转变为数据驱动，网络数据资源呈指数级增长，且散落在不同的数据源之中。对大多数企业和研究者而言，用“数据说话”仿佛成了大数据时代的重要武器。网络爬虫作为网络数据获取的重要技术，受到了越来越多数据需求者的青睐和追捧。
本次分享主要在介绍网络爬虫基本原理的同时，注重具体的代码实现，加深读者对爬虫的理解，加强读者的实战能力。


## 爬虫分类 ##
- 按链接的访问层次的先后来分
	宽度优先和深度优先。
	宽度优先：即在下载网页链接时，是以一层一层的链接来爬取。
![Mou icon](http://images.gitbook.cn/a1410cd0-7dce-11e8-8748-9f97e9dc7c3b)
	深度优化：以先访每层中第一个未访问节点为先，依次下行迭代循环。
![Mou icon](http://images.gitbook.cn/8fd1dab0-7dce-11e8-8a07-2345656531ad)
	宽度和广度混和方式：nutch就是典行的支持这种方式。depth=3,topN=50

- 按爬虫应用来分
	漫爬型爬虫：百度、谷歌爬虫，没有目标，以链接为中心去爬，不限制站点的数据，数据存储直接为单个网页的文本，不进行格式化方面的抽取，一般只做正文、接要、主题词等的抽取，方便索引和搜索。
	垂直型爬虫：内容聚焦，比如说淘宝爬虫、微博爬虫、电商爬虫，而且往往数据直接格式化为结构化数据。


## 爬虫的一般做法 ##
1. 基于Socket通信编写爬虫
	   最底层的实现形式，也是执行最高效，但开发效率较低的一种方式。
	   socket并不是什么通信协议，只是为了方便tcp/ip层的上层访问tip/ip层而做一层封装。
	   相当于http访问socket,而后socket转化为tcp/ip包。
1. 基于HttpURLConnection类编写爬虫
	   JavaSE的net包中的核心类，主要用于http的相关操作。
1. 基于apache的HttpClient包编写爬虫
	   核心也是基于javaSE的net包扩展而来，专为java的网络通信编程而开发的第三方包，也是apache。
1. 基于phantomjs之类的无头（无界面）浏览器
	   （1）它是浏览器核心，并非浏览器。换言之，它是没有界面UI的浏览器,无头，即无界面。
	   （2）它提供的js api,故它可以方便直接的被各种程序语言调用。
1. 基于Selenium或是WebDriver之类的有头（有界面）浏览器
	   它能直接操作本地的浏览器，与真人操作不同的是，它的操作都是程序触发，省去了人为操作的步骤。

## 系统设计 ##
**模块划分**：提交任务的UI接口层、任务调度层、网络爬取层、数据解析层、数据持久化层
**重难点**  ：  乱码解决、多线程设计、爬取的各参数的灵活配置、反爬代理


## 必备知识 ##
- 数据结构
	List和Set集合的使用。
	Map的使用
	Queue的使用
- 日志工具
	收集异常信息。
- 正则表达式
	解析HTML或JSON的常用方法。
- Java基础知识
	JavaIO流、Java多线程等。

## 爬虫入门 ##
### 第一个爬虫程序 ###
    public class ReptileTest1 {

    public static void main(String args[]) {

	        try {
	            Document document = Jsoup.connect("https://www.baidu.com/").get();
	            String title = document.title();
	            System.out.println("document:" + document);
	            System.out.println("title:" + title);
	        } catch (IOException e) {
	            System.out.println("IO流异常");
	            e.printStackTrace();
	        }
    	}
	}